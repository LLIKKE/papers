{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T01:39:58.248768Z",
     "start_time": "2025-05-23T01:39:56.489964Z"
    }
   },
   "source": [
    "import openreview\n",
    "\n",
    "# 若你需要使用旧版 API\n",
    "client = openreview.api.OpenReviewClient(\n",
    "    baseurl='https://api2.openreview.net',\n",
    "    username='like2248@163.com',\n",
    "    password='LIke12345.'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T01:39:58.255589Z",
     "start_time": "2025-05-23T01:39:58.251781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conference = [\"ACL\",\"ICML\",\"ICLR\",\"NeurIPS\"]\n",
    "\n",
    "CF = \"ICLR\"\n",
    "year = \"2025\""
   ],
   "id": "d1b7c49bc8abcc18",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T01:39:58.705356Z",
     "start_time": "2025-05-23T01:39:58.256594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "get_venues = lambda client: client.get_group(id='venues').members\n",
    "venues = get_venues(client)\n",
    "print(len(venues)) \n",
    "venue_id = None\n",
    "# venues[0] ICML.cc/2018/Workshop\n",
    "for venue in venues:\n",
    "    if CF in venue and year in venue and \"Conference\" in venue:\n",
    "        print(venue)\n",
    "        venue_id=venue"
   ],
   "id": "195228157d8fc1b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2555\n",
      "ICLR.cc/2025/Conference\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T01:40:04.277527Z",
     "start_time": "2025-05-23T01:40:04.272368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_submissions(client, venue_id, status='all'):\n",
    "    # Retrieve the venue group information\n",
    "    venue_group = client.get_group(venue_id)\n",
    "    \n",
    "    # Define the mapping of status to the respective content field\n",
    "    status_mapping = {\n",
    "        \"all\": venue_group.content['submission_name']['value'],\n",
    "        \"accepted\": venue_group.id,  # Assuming 'accepted' status doesn't have a direct field\n",
    "        \"under_review\": venue_group.content['submission_venue_id']['value'],\n",
    "        \"withdrawn\": venue_group.content['withdrawn_venue_id']['value'],\n",
    "        \"desk_rejected\": venue_group.content['desk_rejected_venue_id']['value']\n",
    "    }\n",
    "    print(status_mapping)\n",
    "    # Fetch the corresponding submission invitation or venue ID\n",
    "    if status in status_mapping:\n",
    "        if status == \"all\":\n",
    "            # Return all submissions regardless of their status\n",
    "            return client.get_all_notes(invitation=f'{venue_id}/-/{status_mapping[status]}')\n",
    "        \n",
    "        # For all other statuses, use the content field 'venueid'\n",
    "        return client.get_all_notes(content={'venueid': status_mapping[status]})\n",
    "    \n",
    "    raise ValueError(f\"Invalid status: {status}. Valid options are: {list(status_mapping.keys())}\")\n"
   ],
   "id": "6ea3b85995054768",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T01:40:10.361563Z",
     "start_time": "2025-05-23T01:40:05.964805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submissions = get_submissions(client, venue_id, 'accepted')\n",
    "#print(submissions[0])\n",
    "print(len(submissions))\n"
   ],
   "id": "75cf4b8487fd5752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 'Submission', 'accepted': 'ICLR.cc/2025/Conference', 'under_review': 'ICLR.cc/2025/Conference/Submission', 'withdrawn': 'ICLR.cc/2025/Conference/Withdrawn_Submission', 'desk_rejected': 'ICLR.cc/2025/Conference/Desk_Rejected_Submission'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3700/3704 [00:02<00:00, 1521.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:40:04.837932Z",
     "start_time": "2025-05-22T12:40:04.834315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(submissions[0].content)\n",
    "for paper in submissions:\n",
    "    #print(f\"Paper ID: {paper.id}\") # string\n",
    "    #print(f\"Title: {paper.content['title']['value']}\")# string\n",
    "    #print(f\"keywords: {paper.content['keywords']['value']}\") # list\n",
    "    #print(f\"Abstract: {paper.content['abstract']['value']}\") # string\n",
    "    print(f\"PDF: {paper.content['pdf']['value']}\") # list\n",
    "    print('---')\n",
    "    break"
   ],
   "id": "ea8dd285fe298a33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: /pdf/5258198d4d738e054b9e119c78ec513874dfa67d.pdf\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T01:40:58.532973Z",
     "start_time": "2025-05-23T01:40:58.434933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# 构造要保存的数据\n",
    "papers_data = []\n",
    "\n",
    "for paper in submissions:\n",
    "    paper_info = {\n",
    "        \"id\": paper.id,\n",
    "        \"title\": paper.content['title']['value'],\n",
    "        \"keywords\": paper.content['keywords']['value'],\n",
    "        \"abstract\": paper.content['abstract']['value'],\n",
    "        \"authors\": paper.content['authors']['value'],\n",
    "        \"pdf\": paper.content['pdf']['value']\n",
    "    }\n",
    "    papers_data.append(paper_info)\n",
    "import os\n",
    "import json\n",
    "print(len(papers_data))\n",
    "filename = f'paper_list/{CF}_{year}.json'\n",
    "if not os.path.exists(filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers_data, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    print(f\"文件 {filename} 已存在，跳过保存\")"
   ],
   "id": "92321f61a91eccd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:40:38.845207Z",
     "start_time": "2025-05-22T12:40:38.581180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-823fc37d344844128a4bbd02e690d198\", base_url=\"https://api.deepseek.com\")\n",
    "message=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=message,\n",
    "    stream=False\n",
    ")\n",
    "message.append({\"role\": response.choices[0].role, \"content\": \"Hello\"}) # 'assistant'\n",
    "print(response.choices[0])\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "9910ccc2b6fb5592",
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "Failed to deserialize the JSON body into the target type: messages[0][0]: invalid type: map, expected variant identifier at line 1 column 14",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnprocessableEntityError\u001B[39m                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      5\u001B[39m client = OpenAI(api_key=\u001B[33m\"\u001B[39m\u001B[33msk-823fc37d344844128a4bbd02e690d198\u001B[39m\u001B[33m\"\u001B[39m, base_url=\u001B[33m\"\u001B[39m\u001B[33mhttps://api.deepseek.com\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m message=[\n\u001B[32m      7\u001B[39m         {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33msystem\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mYou are a helpful assistant\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m      8\u001B[39m         {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mHello\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m      9\u001B[39m     ],\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m response = client.chat.completions.create(\n\u001B[32m     11\u001B[39m     model=\u001B[33m\"\u001B[39m\u001B[33mdeepseek-chat\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     12\u001B[39m     messages=message,\n\u001B[32m     13\u001B[39m     stream=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     14\u001B[39m )\n\u001B[32m     15\u001B[39m message.append({\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: response.choices[\u001B[32m0\u001B[39m].role, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mHello\u001B[39m\u001B[33m\"\u001B[39m}) \u001B[38;5;66;03m# 'assistant'\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mprint\u001B[39m(response.choices[\u001B[32m0\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda\\envs\\ML\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    285\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda\\envs\\ML\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    882\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    883\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    884\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    922\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    923\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m    924\u001B[39m     validate_response_format(response_format)\n\u001B[32m--> \u001B[39m\u001B[32m925\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m    926\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/chat/completions\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    927\u001B[39m         body=maybe_transform(\n\u001B[32m    928\u001B[39m             {\n\u001B[32m    929\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: messages,\n\u001B[32m    930\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m    931\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33maudio\u001B[39m\u001B[33m\"\u001B[39m: audio,\n\u001B[32m    932\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfrequency_penalty\u001B[39m\u001B[33m\"\u001B[39m: frequency_penalty,\n\u001B[32m    933\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunction_call\u001B[39m\u001B[33m\"\u001B[39m: function_call,\n\u001B[32m    934\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfunctions\u001B[39m\u001B[33m\"\u001B[39m: functions,\n\u001B[32m    935\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogit_bias\u001B[39m\u001B[33m\"\u001B[39m: logit_bias,\n\u001B[32m    936\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogprobs\u001B[39m\u001B[33m\"\u001B[39m: logprobs,\n\u001B[32m    937\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_completion_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_completion_tokens,\n\u001B[32m    938\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_tokens,\n\u001B[32m    939\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m    940\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodalities\u001B[39m\u001B[33m\"\u001B[39m: modalities,\n\u001B[32m    941\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mn\u001B[39m\u001B[33m\"\u001B[39m: n,\n\u001B[32m    942\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mparallel_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: parallel_tool_calls,\n\u001B[32m    943\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprediction\u001B[39m\u001B[33m\"\u001B[39m: prediction,\n\u001B[32m    944\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mpresence_penalty\u001B[39m\u001B[33m\"\u001B[39m: presence_penalty,\n\u001B[32m    945\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mreasoning_effort\u001B[39m\u001B[33m\"\u001B[39m: reasoning_effort,\n\u001B[32m    946\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mresponse_format\u001B[39m\u001B[33m\"\u001B[39m: response_format,\n\u001B[32m    947\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mseed\u001B[39m\u001B[33m\"\u001B[39m: seed,\n\u001B[32m    948\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mservice_tier\u001B[39m\u001B[33m\"\u001B[39m: service_tier,\n\u001B[32m    949\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstop\u001B[39m\u001B[33m\"\u001B[39m: stop,\n\u001B[32m    950\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstore\u001B[39m\u001B[33m\"\u001B[39m: store,\n\u001B[32m    951\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m    952\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream_options\u001B[39m\u001B[33m\"\u001B[39m: stream_options,\n\u001B[32m    953\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m    954\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtool_choice\u001B[39m\u001B[33m\"\u001B[39m: tool_choice,\n\u001B[32m    955\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtools\u001B[39m\u001B[33m\"\u001B[39m: tools,\n\u001B[32m    956\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_logprobs\u001B[39m\u001B[33m\"\u001B[39m: top_logprobs,\n\u001B[32m    957\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m    958\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m    959\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mweb_search_options\u001B[39m\u001B[33m\"\u001B[39m: web_search_options,\n\u001B[32m    960\u001B[39m             },\n\u001B[32m    961\u001B[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001B[32m    962\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[32m    963\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001B[32m    964\u001B[39m         ),\n\u001B[32m    965\u001B[39m         options=make_request_options(\n\u001B[32m    966\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m    967\u001B[39m         ),\n\u001B[32m    968\u001B[39m         cast_to=ChatCompletion,\n\u001B[32m    969\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    970\u001B[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001B[32m    971\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda\\envs\\ML\\Lib\\site-packages\\openai\\_base_client.py:1239\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1225\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1226\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1227\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1234\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1235\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1236\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1237\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1238\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1239\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda\\envs\\ML\\Lib\\site-packages\\openai\\_base_client.py:1034\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1031\u001B[39m             err.response.read()\n\u001B[32m   1033\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1034\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1036\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mUnprocessableEntityError\u001B[39m: Failed to deserialize the JSON body into the target type: messages[0][0]: invalid type: map, expected variant identifier at line 1 column 14"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:04:52.789833Z",
     "start_time": "2025-05-22T12:04:52.787966Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e7e3cacc5709acdf",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7facc4b92401138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
