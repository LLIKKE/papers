[
    {
        "id": "zxg6601zoc",
        "title": "Re-Imagining Multimodal Instruction Tuning: A Representation View",
        "keywords": [
            "Representation Tuning",
            "Large Multimodal Models",
            "Parameter-efficient Fine-tuning"
        ],
        "abstract": "Multimodal instruction tuning has proven to be an effective strategy for achieving zero-shot generalization by fine-tuning pre-trained Large Multimodal Models (LMMs) with instruction-following data. However, as the scale of LMMs continues to grow, fully fine-tuning these models has become highly parameter-intensive. Although Parameter-Efficient Fine-Tuning (PEFT) methods have been introduced to reduce the number of tunable parameters, a significant performance gap remains compared to full fine-tuning. Furthermore, existing PEFT approaches are often highly parameterized, making them difficult to interpret and control. In light of this, we introduce Multimodal Representation Tuning (MRT), a novel approach that focuses on directly editing semantically rich multimodal representations to achieve strong performance and provide intuitive control over LMMs. Empirical results show that our method surpasses current state-of-the-art baselines with significant performance gains (e.g., 1580.40 MME score) while requiring substantially fewer tunable parameters (e.g., 0.03% parameters). Additionally, we conduct experiments on editing instrumental tokens within multimodal representations, demonstrating that direct manipulation of these representations enables simple yet effective control over network behavior.",
        "authors": [
            "Yiyang Liu",
            "James Chenhao Liang",
            "Ruixiang Tang",
            "Yugyung Lee",
            "MAJID RABBANI",
            "Sohail Dianat",
            "Raghuveer Rao",
            "Lifu Huang",
            "Dongfang Liu",
            "Qifan Wang",
            "Cheng Han"
        ],
        "pdf": "/pdf/5258198d4d738e054b9e119c78ec513874dfa67d.pdf"
    },
    {
        "id": "zxO4WuVGns",
        "title": "Inverse decision-making using neural amortized Bayesian actors",
        "keywords": [
            "Bayesian actor models",
            "perception and action",
            "cognitive science",
            "Bayesian inference",
            "inverse modeling"
        ],
        "abstract": "Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more naturalistic tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Inverse decision-making, i.e. performing inference over the parameters of such models given behavioral data, is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical approximations. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing efficient gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show how our method allows for principled model comparison and how it can be used to disentangle factors that may lead to unidentifiabilities between priors and costs. Finally, we apply our method to empirical data from three sensorimotor tasks and compare model fits with different cost functions to show that it can explain individuals' behavioral patterns.",
        "authors": [
            "Dominik Straub",
            "Tobias F. Niehues",
            "Jan Peters",
            "Constantin A. Rothkopf"
        ],
        "pdf": "/pdf/0046d112b652872ab73840e86afeae102f289d1c.pdf"
    }
]